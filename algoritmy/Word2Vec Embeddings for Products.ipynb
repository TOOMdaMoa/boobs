{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part 1 \n",
    "---------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Import packages we will use \n",
    "import json\n",
    "import pprint \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import collections \n",
    "import tensorflow as tf\n",
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(11262017)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Read the data, one line (= one json) at a time \n",
    "file = open(\"products-sample.json\")\n",
    "\n",
    "data = []\n",
    "\n",
    "for line in file:\n",
    "    data.append(json.loads(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is how one json looks like: \n",
      "\n",
      "{'brand': {...},\n",
      " 'brief_plain': {...},\n",
      " 'date': '2017-11-15T08:40:00.822Z',\n",
      " 'product_id': '1043735',\n",
      " 'product_type': {...},\n",
      " 'title_full': {...},\n",
      " 'user_id': 'f193a03cabf477202d7c342a8d199460',\n",
      " 'variant_data': [...],\n",
      " 'variant_id': '1043735004'}\n",
      "\n",
      "\n",
      "There are 106 jsons in the data\n"
     ]
    }
   ],
   "source": [
    "## Explore the data \n",
    "print(\"This is how one json looks like: \\n\")\n",
    "pprint.pprint(data[9], depth=1)\n",
    "## pprint.pprint(data[0][\"variant_data\"][0][\"params\"], depth=4)\n",
    "\n",
    "print(\"\\n\\nThere are\", len(data), \"jsons in the data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part 2\n",
    "--------------\n",
    "\n",
    "Now we will create list \"groups\" which will have structure\n",
    "\n",
    "[ [ids of products of customer 1], \n",
    "  [ids of products of customer 2],\n",
    "  .\n",
    "  .\n",
    "  .\n",
    "  [ids of products of customer n] ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Create dataframe with columns \"user_id\", \"product_id\"\n",
    "user_product = pd.DataFrame([{\"user\": j[\"user_id\"], \"product\" : j[\"product_id\"]} for j in data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Group \"user_product\" by user, select groups with at least 2 elements \n",
    "grouping = user_product.groupby(by=[\"user\"])\n",
    "group_series = grouping.product.apply(list)\n",
    "group_counts = list(grouping.count().iloc[:,0])\n",
    "at_least_2 = [x>1 for x in group_counts]\n",
    "groups = list(group_series[at_least_2])\n",
    "group_counts = [group_counts[i] for i in range(len(at_least_2)) if at_least_2[i]] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "These are the groups: \n",
      "\n",
      "[['935880', '935804'],\n",
      " ['1079941', '1079941'],\n",
      " ['1036818', '1067651'],\n",
      " ['1074485', '1070850'],\n",
      " ['1012091', '1077488'],\n",
      " ['1036823', '1063697', '1036823'],\n",
      " ['937412', '1079350'],\n",
      " ['1073114', '1069170', '996046', '1012185', '996046'],\n",
      " ['1076284', '1076361'],\n",
      " ['1085963', '1085963'],\n",
      " ['935880', '935880'],\n",
      " ['1091285', '1091285'],\n",
      " ['847827', '847829'],\n",
      " ['1039048', '1067061']]\n",
      "\n",
      "\n",
      "There are 14 groups\n"
     ]
    }
   ],
   "source": [
    "## Explore the groups (each representing a customer who viewed details of at least 2 products)\n",
    "## Notice that sometimes there are two identical products in one group (user viewed it twice)\n",
    "print(\"These are the groups: \\n\")\n",
    "pprint.pprint(groups)\n",
    "\n",
    "print(\"\\n\\nThere are\", len(groups), \"groups\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part 3\n",
    "-----------------\n",
    "\n",
    "The rest of this notebook is heavily based on https://www.tensorflow.org/tutorials/word2vec\n",
    "\n",
    "The code is not very clean\n",
    "\n",
    "For each product (that is for each word in the terminology of word2vec) we learn its vector representation aka embedding\n",
    "\n",
    "This vector representation is designed in such a way that similar products (in the sense that they appear often together in one customers list) will have similar vectors (measured in standard eucleidean distance) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_words = 50000\n",
    "words = [x for y in groups for x in y]\n",
    "counts = collections.Counter(words).most_common(n_words - 1)\n",
    "dictionary = dict()\n",
    "for word, _ in counts:\n",
    "        dictionary[word] = len(dictionary)\n",
    "reversed_dictionary = dict(zip(dictionary.values(), dictionary.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nr_contexts = len(group_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_batch(batch_size = 8):\n",
    "    \"\"\" Creates batch of radnomly selected word indices and their context word indices\n",
    "    \n",
    "        Arguments:\n",
    "        batch_size -- len of word indices and context word indices \n",
    "        \n",
    "        Return: \n",
    "        batch -- word indices\n",
    "        labels -- context word indices \n",
    "    \"\"\"\n",
    "    batch = []\n",
    "    labels = []\n",
    "    ## select randomly word + word from context \n",
    "    ## first select randomly contexts (we select context with probability proportional to its number of words)\n",
    "    contexts_sample = np.random.multinomial(n = batch_size, pvals = group_counts/sum(group_counts))\n",
    "    for i in range(nr_contexts):\n",
    "        for j in range(contexts_sample[i]):\n",
    "            group_i = groups[i]\n",
    "            ii = np.random.choice(len(group_i), 2, replace=True)\n",
    "            batch.append(dictionary[group_i[ii[0]]])\n",
    "            labels.append(dictionary[group_i[ii[1]]])\n",
    "    return np.array(batch), np.array(labels).reshape((-1,1))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Size of training batch\n",
    "batch_size = 16\n",
    "\n",
    "## Length of word embedding vector\n",
    "embedding_size = 16\n",
    "\n",
    "## Number of distinct words\n",
    "vocabulary_size = len(counts)\n",
    "\n",
    "## Number of negative examples, see nonnegative sampling \n",
    "num_sampled = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Definition of tensorflow model\n",
    "## this is basically copied source code from the link above\n",
    "\n",
    "train_inputs = tf.placeholder(tf.int32, shape=[batch_size])\n",
    "train_labels = tf.placeholder(tf.int32, shape=[batch_size, 1])\n",
    "\n",
    "embeddings = tf.Variable(tf.random_uniform([vocabulary_size, embedding_size], -1.0, 1.0))\n",
    "embed = tf.nn.embedding_lookup(embeddings, train_inputs)\n",
    "\n",
    "nce_weights = tf.Variable(\n",
    "            tf.truncated_normal([vocabulary_size, embedding_size],\n",
    "                            stddev=1.0 / np.sqrt(embedding_size)))\n",
    "nce_biases = tf.Variable(tf.zeros([vocabulary_size]))\n",
    "\n",
    "loss = tf.reduce_mean(\n",
    "            tf.nn.nce_loss(weights=nce_weights,\n",
    "                           biases=nce_biases,\n",
    "                           labels=train_labels,\n",
    "                           inputs=embed,\n",
    "                           num_sampled=num_sampled,\n",
    "                           num_classes=vocabulary_size))\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(1.0).minimize(loss)\n",
    "\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Learn the embeddings\n",
    "for i in range(30000): \n",
    "    batch, labels = create_batch(batch_size)\n",
    "    sess.run(optimizer, {train_inputs : batch, train_labels : labels})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Embeddings matrix (each row is embedding of one word) \n",
    "E = sess.run(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25, 16)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "E.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can display the embeddings using a technique called t-SNE, this basicaly maps the 16 dimensional vectors to 2 dimensional vectors in a way that vectors that had small eucleidean distance in the 16 dimensions will have small eucleidean distance in the 2 dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25, 2)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "E_embedded = TSNE(n_components=2).fit_transform(E)\n",
    "E_embedded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['blue', 'blue', 'blue', 'blue', 'blue', 'red', 'blue', 'blue',\n",
       "       'blue', 'blue', 'blue', 'blue', 'red', 'red', 'blue', 'blue',\n",
       "       'blue', 'blue', 'blue', 'blue', 'blue', 'blue', 'blue', 'blue',\n",
       "       'red'], \n",
       "      dtype='<U4')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "customer_7 = np.repeat(\"blue\", E.shape[0])\n",
    "customer_7[[i for k,i in dictionary.items() if k in groups[7]]] = \"red\"\n",
    "customer_7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can plot TSNE of the embeddings, notice that for example items of one customer are close together "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX8AAAD8CAYAAACfF6SlAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1dc87909ba8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(E[:,0], E[:,1], c=customer_7)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
